{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sgmatch.models.GMN import GMNEmbed,GMNMatch\n",
    "import torch\n",
    "from torch_geometric.utils.random import erdos_renyi_graph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import tqdm\n",
    "from tests.utils.data import PairData\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletData(Data):\n",
    "    def __init__(self, edge_index_1=None, x_1=None, \n",
    "                edge_index_2=None, x_2=None, edge_index_3=None,x_3=None,y=None):\n",
    "        super(TripletData, self).__init__()  # Call the parent class constructor here\n",
    "        self.edge_index_1 = edge_index_1\n",
    "        self.x_1 = x_1\n",
    "        self.edge_index_2 = edge_index_2\n",
    "        self.x_2 = x_2\n",
    "        self.edge_index_3 = edge_index_3\n",
    "        self.x_3 = x_3\n",
    "        self.y = y\n",
    "\n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        if key == 'edge_index_1':\n",
    "            return self.x_1.size(0)\n",
    "        if key == 'edge_index_2':\n",
    "            return self.x_2.size(0)\n",
    "        if key == 'edge_index_3':\n",
    "            return self.x_3.size(0)\n",
    "        else:\n",
    "            return super().__inc__(key, value, *args, **kwargs)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '{}(x_1 = {}, edge_index_1 = {}, x_2 = {}, edge_index_2 = {}, x_3 = {}, edge_index_3 = {})'.format(\n",
    "            self.__class__.__name__, self.x_1.shape, self.edge_index_1.shape,\n",
    "            self.x_2.shape, self.edge_index_2.shape, self.x_3.shape, self.edge_index_3.shape\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairData(Data):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, edge_index_s=None, x_s=None, \n",
    "                edge_index_t=None, x_t=None, y=None):\n",
    "        super(PairData, self).__init__()\n",
    "        self.edge_index_s = edge_index_s\n",
    "        self.x_s = x_s\n",
    "        self.edge_index_t = edge_index_t\n",
    "        self.x_t = x_t\n",
    "        self.y = y\n",
    "\n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        if key == 'edge_index_s':\n",
    "            return self.x_s.size(0)\n",
    "        if key == 'edge_index_t':\n",
    "            return self.x_t.size(0)\n",
    "        else:\n",
    "            return super().__inc__(key, value, *args, **kwargs)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}(x_s = {}, edge_index_s = {}, x_t = {}, edge_index_t = {}, y = {})'.format(\n",
    "            self.__class__.__name__, self.x_s.shape, self.edge_index_s.shape,\n",
    "            self.x_t.shape, self.edge_index_t.shape, self.y.shape\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_graphs(num_nodes,edge_probability,size,kp=1,kn=2):\n",
    "    G1=[] #Random binomial drawn graphs\n",
    "    G2=[] #Graphs obtained by replacing kp edges to find positive graphs to G1\n",
    "    G3=[] #Graphs obtained by replacing kn edges to find negative graphs to G2\n",
    "\n",
    "    with tqdm.tqdm(total=size,desc=\"Creating Graphs:\") as bar:\n",
    "        for _ in range(size):\n",
    "            e1=erdos_renyi_graph(num_nodes,edge_probability)\n",
    "\n",
    "            id=torch.randint(0,e1.shape[1],(kp,))\n",
    "            indices1=[e for e in range(e1.shape[1]) if e not in id]\n",
    "            \n",
    "            e2=e1[:,indices1]\n",
    "\n",
    "            id=torch.randint(0,e1.shape[1],(kn,))\n",
    "            indices2=[e for e in range(e1.shape[1]) if e not in id]\n",
    "\n",
    "            e3=e1[:,indices2]\n",
    "\n",
    "            data=Data(x=torch.ones(num_nodes,32),edge_index=e1,num_nodes=num_nodes)\n",
    "            data1=Data(x=torch.ones(num_nodes,32),edge_index=e2,num_nodes=num_nodes)\n",
    "            data2=Data(x=torch.ones(num_nodes,32),edge_index=e3,num_nodes=num_nodes)\n",
    "\n",
    "            G1.append(data)\n",
    "            G2.append(data1)\n",
    "            G3.append(data2)\n",
    "\n",
    "            bar.update(1)\n",
    "    return G1,G2,G3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMN_loss(torch.nn.Module):\n",
    "    def __init__(self, weight=None, size_average=None, reduce=None, reduction='mean'):\n",
    "        super(GMN_loss, self).__init__()\n",
    "\n",
    "    def forward(self, g1_pred,g2_pred,g3_pred,gamma):\n",
    "        loss=torch.sqrt(torch.sum(torch.pow(torch.subtract(g1_pred.reshape((g1_pred.shape[-1],)), g2_pred.reshape((g1_pred.shape[-1],))), 2), dim=0))-torch.sqrt(torch.sum(torch.pow(torch.subtract(g1_pred.reshape((g1_pred.shape[-1],)),g3_pred.reshape((g1_pred.shape[-1],))), 2), dim=0))+gamma\n",
    "        #print(loss.shape)\n",
    "        loss=torch.maximum(torch.tensor(0),loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g1_train, g1_val,g2_train, g2_val,g3_train, g3_val, model, loss_criterion, optimizer, device, num_epochs=10, gamma=0.1):\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss_sum = 0\n",
    "        val_loss_sum = 0\n",
    "        with tqdm.tqdm(total=len(g1_train)*len(g1_train[0]), desc='Train batches completed: ') as bar:\n",
    "            for i in range(len(g1_train)):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                batch_loss=0\n",
    "                for j in range(len(g1_train[0])):\n",
    "                    \n",
    "                    g1_pred = model(g1_train[i][j].x, g1_train[i][j].edge_index)\n",
    "                    g2_pred = model(g2_train[i][j].x, g2_train[i][j].edge_index)\n",
    "                    g3_pred = model(g3_train[i][j].x, g3_train[i][j].edge_index)\n",
    "                    \n",
    "                    batch_loss += loss_criterion(g1_pred,g2_pred,g3_pred,gamma)\n",
    "                    # Compute Gradients via Backpropagation\n",
    "                \n",
    "                train_loss_sum+=batch_loss\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                bar.update(len(g1_train[0]))\n",
    "\n",
    "        with tqdm.tqdm(total=len(g1_val)*len(g1_val[0]), desc='Validation batches completed: ') as bar:\n",
    "            for i in range(len(g1_val)):\n",
    "                model.eval()\n",
    "                batch_loss=0\n",
    "                for j in range(len(g1_val[0])):\n",
    "                    with torch.no_grad():\n",
    "                        g1_pred = model(g1_val[i][j].x, g1_val[i][j].edge_index)\n",
    "                        g2_pred = model(g2_val[i][j].x, g2_val[i][j].edge_index)\n",
    "                        g3_pred = model(g3_val[i][j].x, g3_val[i][j].edge_index)\n",
    "                        \n",
    "                        batch_loss += loss_criterion(g1_pred,g2_pred,g3_pred,gamma)\n",
    "                val_loss_sum+=batch_loss\n",
    "                bar.update(len(g1_val[0]))\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache() \n",
    "    \n",
    "        # Printing Epoch Summary\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs} | Per Graph Train MSE: {train_loss_sum / (len(g1_train)*len(g1_train[0]))} | Per Graph Validation MSE: {val_loss_sum / (len(g1_val)*len(g1_val[0]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Graphs::   0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Graphs:: 100%|██████████| 100000/100000 [08:09<00:00, 204.26it/s]\n"
     ]
    }
   ],
   "source": [
    "G1,G2,G3=create_graphs(20,0.3,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_batchwise(dataset,batch_size):\n",
    "    l=len(dataset)\n",
    "    batched_dataset=[]\n",
    "    prev=0\n",
    "    for i in range(0,l,batch_size):\n",
    "        if i==0:\n",
    "            prev=i\n",
    "            continue\n",
    "        if i<l:\n",
    "            batched_dataset.append(dataset[prev:i])\n",
    "            prev=i\n",
    "        else:\n",
    "            batched_dataset.append(dataset[prev:])\n",
    "\n",
    "    return batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=int(0.65*len(G1))\n",
    "t2=int(0.75*len(G1))\n",
    "t1=10000\n",
    "t2=15000\n",
    "t3=20000\n",
    "\n",
    "g1_train=divide_batchwise(G1[:t1],128)\n",
    "g1_val=divide_batchwise(G1[t1+1:t2],64)\n",
    "g1_test=divide_batchwise(G1[t2+1:t3],256)\n",
    "\n",
    "g2_train=divide_batchwise(G2[:t1],128)\n",
    "g2_val=divide_batchwise(G2[t1+1:t2],64)\n",
    "g2_test=divide_batchwise(G2[t2+1:t3],256)\n",
    "\n",
    "g3_train=divide_batchwise(G3[:t1],128)\n",
    "g3_val=divide_batchwise(G3[t1+1:t2],64)\n",
    "g3_test=divide_batchwise(G3[t2+1:t3],256)\n",
    "\n",
    "\n",
    "D=32\n",
    "learning_rate=0.01\n",
    "\n",
    "mlp_layers=[32,16,8]\n",
    "\n",
    "model = GMNEmbed(node_feature_dim=g1_train[0][0].x.shape[-1], \n",
    "                enc_node_hidden_sizes=mlp_layers,\n",
    "                prop_node_hidden_sizes=mlp_layers,\n",
    "                prop_message_hidden_sizes=mlp_layers,\n",
    "                aggr_gate_hidden_sizes=mlp_layers,\n",
    "                aggr_mlp_hidden_sizes=mlp_layers)\n",
    "\n",
    "criterion=GMN_loss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),learning_rate)\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1_pred=torch.Tensor([1,2,3,4])\n",
    "g2_pred=torch.Tensor([2,3,4,5])\n",
    "\n",
    "#g1_pred.reshape((1,4))\n",
    "torch.sum(torch.pow(torch.subtract(g1_pred, g2_pred), 2), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batches completed: 100%|██████████| 9984/9984 [10:07<00:00, 16.43it/s]\n",
      "Validation batches completed: 100%|██████████| 4992/4992 [00:52<00:00, 95.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 | Per Graph Train MSE: 0.01587802544236183 | Per Graph Validation MSE: 0.001015839516185224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batches completed: 100%|██████████| 9984/9984 [04:24<00:00, 37.68it/s]\n",
      "Validation batches completed: 100%|██████████| 4992/4992 [00:39<00:00, 126.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10 | Per Graph Train MSE: 0.0010457339230924845 | Per Graph Validation MSE: 0.0010046048555523157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batches completed: 100%|██████████| 9984/9984 [03:32<00:00, 46.90it/s]\n",
      "Validation batches completed: 100%|██████████| 4992/4992 [00:49<00:00, 99.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10 | Per Graph Train MSE: 0.0010171567555516958 | Per Graph Validation MSE: 0.0010043588699772954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batches completed: 100%|██████████| 9984/9984 [1:38:37<00:00,  1.69it/s]   \n",
      "Validation batches completed: 100%|██████████| 4992/4992 [00:45<00:00, 110.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10 | Per Graph Train MSE: 0.001072034938260913 | Per Graph Validation MSE: 0.0010186285944655538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batches completed: 100%|██████████| 9984/9984 [03:46<00:00, 44.14it/s]\n",
      "Validation batches completed: 100%|██████████| 4992/4992 [00:53<00:00, 92.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10 | Per Graph Train MSE: 0.001011681859381497 | Per Graph Validation MSE: 0.000998842646367848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batches completed: 100%|██████████| 9984/9984 [04:26<00:00, 37.44it/s]\n",
      "Validation batches completed: 100%|██████████| 4992/4992 [00:39<00:00, 127.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10 | Per Graph Train MSE: 0.0010628777090460062 | Per Graph Validation MSE: 0.0010239582043141127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batches completed: 100%|██████████| 9984/9984 [03:13<00:00, 51.59it/s]\n",
      "Validation batches completed: 100%|██████████| 4992/4992 [00:47<00:00, 105.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10 | Per Graph Train MSE: 0.0010465284576639533 | Per Graph Validation MSE: 0.0009733272017911077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batches completed: 100%|██████████| 9984/9984 [1:07:22<00:00,  2.47it/s]   \n",
      "Validation batches completed: 100%|██████████| 4992/4992 [00:55<00:00, 89.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10 | Per Graph Train MSE: 0.001059221918694675 | Per Graph Validation MSE: 0.0010187909938395023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batches completed: 100%|██████████| 9984/9984 [04:58<00:00, 33.41it/s]\n",
      "Validation batches completed: 100%|██████████| 4992/4992 [00:57<00:00, 86.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10 | Per Graph Train MSE: 0.0010597942164167762 | Per Graph Validation MSE: 0.0009998989989981055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batches completed: 100%|██████████| 9984/9984 [05:00<00:00, 33.20it/s]\n",
      "Validation batches completed: 100%|██████████| 4992/4992 [01:03<00:00, 78.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10 | Per Graph Train MSE: 0.0010411114199087024 | Per Graph Validation MSE: 0.0010099589126184583\n"
     ]
    }
   ],
   "source": [
    "train(g1_train, g1_val,g2_train, g2_val,g3_train, g3_val, model, criterion, optimizer, device, num_epochs=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eculdiean_dist(a,b):\n",
    "    return torch.sqrt(torch.sum(torch.pow(torch.subtract(a.reshape((a.shape[-1],)), b.reshape((a.shape[-1],))), 2), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./trained_models/gmn_model.pkl\",'wb') as file:\n",
    "    pickle.dump(model,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 4864/4864 [01:12<00:00, 67.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9919819078947368"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy=0\n",
    "\n",
    "with tqdm.tqdm(total=len(g1_test)*len(g1_test[0]),desc=\"testing: \") as bar:\n",
    "    for i in range(len(g1_test)):\n",
    "        for j in range(len(g1_test[0])):\n",
    "            g1_pred = model(g1_test[i][j].x, g1_test[i][j].edge_index)\n",
    "            g2_pred = model(g2_test[i][j].x, g2_test[i][j].edge_index)\n",
    "            g3_pred = model(g3_test[i][j].x, g3_test[i][j].edge_index)\n",
    "\n",
    "            if abs(eculdiean_dist(g1_pred,g2_pred) - eculdiean_dist(g1_pred,g3_pred)) > 0.1 :\n",
    "                accuracy+=1\n",
    "        bar.update(len(g1_test[0]))\n",
    "\n",
    "accuracy=accuracy/(len(g1_test)*len(g1_test[0]))\n",
    "accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
