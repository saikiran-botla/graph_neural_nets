{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.functional import Tensor\n",
    "from torch_geometric.utils.random import erdos_renyi_graph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import tqdm\n",
    "from tests.utils.data import PairData\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "from sgmatch.models.ISONET import ISONET\n",
    "from tests.utils.dataset import load_dataset\n",
    "from tests.utils.parser import parser\n",
    "from tests.utils.data import PairData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_pairs(train_dataset, test_dataset) -> Tuple[List]:\n",
    "    train_graph_pairs = []\n",
    "    with tqdm.tqdm(total=len(train_dataset)**2, desc='Train graph pairs completed: ') as bar:\n",
    "        for idx1, graph1 in enumerate(train_dataset):\n",
    "            for idx2, graph2 in enumerate(train_dataset):\n",
    "                if idx1 == idx2:\n",
    "                    continue\n",
    "                # Initializing Data\n",
    "                edge_index_s = graph1.edge_index\n",
    "                x_s = graph1.x\n",
    "\n",
    "                edge_index_t = graph2.edge_index\n",
    "                x_t = graph2.x\n",
    "\n",
    "                norm_ged = train_dataset.norm_ged[graph1.i, graph2.i]\n",
    "                graph_sim = 1 if norm_ged<=2 else -1\n",
    "\n",
    "                \n",
    "                # Making Graph Pair\n",
    "                if isinstance(x_s, Tensor) and isinstance(x_t, Tensor):\n",
    "                    graph_pair = PairData(edge_index_s=edge_index_s, x_s=x_s,\n",
    "                                        edge_index_t=edge_index_t, x_t=x_t,\n",
    "                                        y=graph_sim)\n",
    "                    \n",
    "                    # Saving all the Graph Pairs to the List for Batching and Data Loading\n",
    "                    train_graph_pairs.append(graph_pair)\n",
    "            bar.update(len(train_dataset))\n",
    "    \n",
    "    test_graph_pairs = []\n",
    "    with tqdm.tqdm(total=len(test_dataset)*len(train_dataset), desc='Test graph pairs completed: ') as bar:\n",
    "        for graph1 in test_dataset:\n",
    "            for graph2 in train_dataset:\n",
    "                # Initializing Data\n",
    "                edge_index_s = graph1.edge_index\n",
    "                x_s = graph1.x\n",
    "                edge_index_t = graph2.edge_index\n",
    "                x_t = graph2.x\n",
    "\n",
    "                norm_ged = train_dataset.norm_ged[graph1.i, graph2.i]\n",
    "                graph_sim = 1 if norm_ged<=2 else -1\n",
    "                \n",
    "                # Making Graph Pair\n",
    "                if isinstance(x_s, Tensor) and isinstance(x_t, Tensor):\n",
    "                    graph_pair = PairData(edge_index_s=edge_index_s, x_s=x_s,\n",
    "                                        edge_index_t=edge_index_t, x_t=x_t,\n",
    "                                        y=graph_sim)\n",
    "                \n",
    "                    # Saving all the Graph Pairs to the List for Batching and Data Loading\n",
    "                    test_graph_pairs.append(graph_pair)\n",
    "            bar.update(len(train_dataset))\n",
    "    \n",
    "    return train_graph_pairs, test_graph_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, model, loss_criterion, optimizer, device, num_epochs=10):\n",
    "    batch_train_loss_sum = 0\n",
    "    batch_val_loss_sum = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        with tqdm.tqdm(total=len(train_loader), desc='Train batches completed: ') as bar:\n",
    "            for batch_idx, train_batch in enumerate(train_loader):\n",
    "                model.train()\n",
    "                train_batch = train_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                pred_sim = model(train_batch.x_s,  train_batch.x_t, train_batch.edge_index_s, \n",
    "                                train_batch.edge_index_t)\n",
    "                mean_batch_loss = loss_criterion(pred_sim, train_batch.y)\n",
    "                # Compute Gradients via Backpropagation\n",
    "                mean_batch_loss.backward()\n",
    "                # Update Parameters\n",
    "                optimizer.step()\n",
    "                batch_train_loss_sum += mean_batch_loss.item()*len(train_batch)\n",
    "                \n",
    "                bar.update(1)\n",
    "\n",
    "        with tqdm.tqdm(total=len(val_loader), desc='Validation batches completed: ') as bar:\n",
    "            for batch_idx, val_batch in enumerate(val_loader):\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_batch = val_batch.to(device)\n",
    "                    pred_sim = model(train_batch.x_s,  train_batch.x_t, train_batch.edge_index_s, \n",
    "                                train_batch.edge_index_t)\n",
    "                    mean_val_loss = loss_criterion(pred_sim, val_batch.y)\n",
    "                    batch_val_loss_sum += mean_val_loss.item()*len(val_batch)\n",
    "\n",
    "                bar.update(1)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache() \n",
    "    \n",
    "        # Printing Epoch Summary\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs} | Per Graph Train MSE: {batch_train_loss_sum / len(train_loader.dataset)} | Mean batch loss :{mean_batch_loss} \\n   |Per Graph Validation MSE: {batch_val_loss_sum / len(val_loader.dataset)}| Mean_val_loss: {mean_val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train graph pairs completed:   0%|          | 0/313600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train graph pairs completed: 100%|██████████| 313600/313600 [00:24<00:00, 13060.42it/s]\n",
      "Test graph pairs completed: 100%|██████████| 78400/78400 [00:06<00:00, 11798.93it/s]\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "data_path=\"./data\"\n",
    "train_batch_size=128\n",
    "val_batch_size=64\n",
    "test_batch_size=256\n",
    "learning_rate=0.01\n",
    "\n",
    "train_dataset = load_dataset(dpath=data_path+\"/aids/\", name=\"GED\", category=\"AIDS700nef\", train=True)\n",
    "test_dataset = load_dataset(dpath=data_path+\"/aids/\", name=\"GED\", category=\"AIDS700nef\", train=False)\n",
    "\n",
    "train_ged_table = train_dataset.ged[:train_dataset.data.i[-1]+1, :train_dataset.data.i[-1]+1]\n",
    "test_ged_table = test_dataset.ged[train_dataset.data.i[-1]+1:, train_dataset.data.i[-1]+1:]\n",
    "\n",
    "train_graph_pairs, test_graph_pairs = create_graph_pairs(train_dataset, test_dataset)\n",
    "\n",
    "torch.save(train_graph_pairs, data_path+\"/isonet/aids/graph_pairs/train_graph_pairs.pt\")\n",
    "torch.save(test_graph_pairs, data_path+\"/isonet/aids/graph_pairs/test_graph_pairs.pt\")\n",
    "\n",
    "train_graph_pairs, test_graph_pairs = torch.load(data_path+\"/isonet/aids/graph_pairs/train_graph_pairs.pt\"),\\\n",
    "                                        torch.load(data_path+\"/isonet/aids/graph_pairs/test_graph_pairs.pt\")\n",
    "\n",
    "\n",
    "val_idxs = np.random.randint(len(train_graph_pairs), size=len(test_graph_pairs))\n",
    "val_graph_pairs = [train_graph_pairs[idx] for idx in val_idxs]\n",
    "train_idxs = set(range(len(train_graph_pairs))) - set(val_idxs)\n",
    "train_graph_pairs = [train_graph_pairs[idx] for idx in train_idxs]\n",
    "del val_idxs, train_idxs\n",
    "\n",
    "train_loader = DataLoader(train_graph_pairs, batch_size = 128, follow_batch = [\"x_s\", \"x_t\"], shuffle = True)\n",
    "val_loader = DataLoader(val_graph_pairs, batch_size = 64, follow_batch = [\"x_s\", \"x_t\"], shuffle = True)\n",
    "test_loader = DataLoader(test_graph_pairs, batch_size = 256, follow_batch = [\"x_s\", \"x_t\"], shuffle = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ISONET(node_feature_dim=train_loader.dataset[0].x_s.shape[-1],\n",
    "             enc_node_hidden_sizes=[64,32,16],\n",
    "             prop_node_hidden_sizes=[64,32,16],\n",
    "             prop_message_hidden_sizes=[64,32,16],\n",
    "            )\n",
    "\n",
    "criterion = torch.nn.HingeEmbeddingLoss(margin=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(),learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 18])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0].edge_index_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train batches completed:   0%|          | 0/1905 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1142, 16]) 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 32, got 16",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\saiki\\IITB\\BTP1\\graphretrievaltoolkit-main\\graphretrievaltoolkit-main\\test_isonet.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/saiki/IITB/BTP1/graphretrievaltoolkit-main/graphretrievaltoolkit-main/test_isonet.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(train_loader,val_loader,model,criterion,optimizer,device)\n",
      "\u001b[1;32mc:\\Users\\saiki\\IITB\\BTP1\\graphretrievaltoolkit-main\\graphretrievaltoolkit-main\\test_isonet.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/saiki/IITB/BTP1/graphretrievaltoolkit-main/graphretrievaltoolkit-main/test_isonet.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m train_batch \u001b[39m=\u001b[39m train_batch\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saiki/IITB/BTP1/graphretrievaltoolkit-main/graphretrievaltoolkit-main/test_isonet.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/saiki/IITB/BTP1/graphretrievaltoolkit-main/graphretrievaltoolkit-main/test_isonet.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m pred_sim \u001b[39m=\u001b[39m model(train_batch\u001b[39m.\u001b[39;49mx_s,  train_batch\u001b[39m.\u001b[39;49mx_t, train_batch\u001b[39m.\u001b[39;49medge_index_s, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saiki/IITB/BTP1/graphretrievaltoolkit-main/graphretrievaltoolkit-main/test_isonet.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                 train_batch\u001b[39m.\u001b[39;49medge_index_t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saiki/IITB/BTP1/graphretrievaltoolkit-main/graphretrievaltoolkit-main/test_isonet.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m mean_batch_loss \u001b[39m=\u001b[39m loss_criterion(pred_sim, train_batch\u001b[39m.\u001b[39my)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/saiki/IITB/BTP1/graphretrievaltoolkit-main/graphretrievaltoolkit-main/test_isonet.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Compute Gradients via Backpropagation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\saiki\\IITB\\env_general\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\saiki\\IITB\\BTP1\\graphretrievaltoolkit-main\\graphretrievaltoolkit-main\\sgmatch\\models\\ISONET.py:145\u001b[0m, in \u001b[0;36mISONET.forward\u001b[1;34m(self, node_features_q, node_features_c, edge_index_q, edge_index_c, edge_features_q, edge_features_c, batch_q, batch_c, num_prop)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, node_features_q: Tensor, node_features_c: Tensor, edge_index_q: Tensor, edge_index_c: Tensor,\n\u001b[0;32m    141\u001b[0m             edge_features_q: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, edge_features_c: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \n\u001b[0;32m    142\u001b[0m             batch_q: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, batch_c: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, num_prop: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m):\n\u001b[0;32m    143\u001b[0m     \n\u001b[0;32m    144\u001b[0m     \u001b[39m# Computes r_(u,v)_(K)\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m     edge_features_q \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_edges(node_features_q, edge_index_q, edge_features_q, num_prop)\n\u001b[0;32m    146\u001b[0m     edge_features_c \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_edges(node_features_c, edge_index_c, edge_features_c, num_prop)\n\u001b[0;32m    149\u001b[0m     \u001b[39m# Once we have the Node and Edge Embeddings, we create R_q and R_c Matrices\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\saiki\\IITB\\BTP1\\graphretrievaltoolkit-main\\graphretrievaltoolkit-main\\sgmatch\\models\\ISONET.py:128\u001b[0m, in \u001b[0;36mISONET.embed_edges\u001b[1;34m(self, node_features, edge_index, edge_features, num_prop)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39m# This calculates h_u(K)\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_prop):\n\u001b[0;32m    127\u001b[0m     \u001b[39m# TODO: Can include a list keeping track of propagation layer outputs\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     node_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_message_agg_comb(node_features, from_idx, to_idx, edge_features)\n\u001b[0;32m    130\u001b[0m \u001b[39m# Computes r_(u,v)_(K)\u001b[39;00m\n\u001b[0;32m    131\u001b[0m edge_message \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_agg_comb\u001b[39m.\u001b[39m_compute_messages(node_features, from_idx, to_idx,\n\u001b[0;32m    132\u001b[0m                                                                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_agg_comb\u001b[39m.\u001b[39mmessage_net,\n\u001b[0;32m    133\u001b[0m                                                                 edge_features\u001b[39m=\u001b[39medge_features)\n",
      "File \u001b[1;32mc:\\Users\\saiki\\IITB\\env_general\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\saiki\\IITB\\BTP1\\graphretrievaltoolkit-main\\graphretrievaltoolkit-main\\sgmatch\\modules\\propagation.py:249\u001b[0m, in \u001b[0;36mGraphProp.forward\u001b[1;34m(self, node_features, from_idx, to_idx, node_features_j, edge_features, att_module)\u001b[0m\n\u001b[0;32m    247\u001b[0m     node_input_list\u001b[39m.\u001b[39mappend(att_features)\n\u001b[0;32m    248\u001b[0m \u001b[39mprint\u001b[39m(node_features\u001b[39m.\u001b[39mshape,\u001b[39mlen\u001b[39m(node_input_list))\n\u001b[1;32m--> 249\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_node_update(node_features, node_input_list)\n\u001b[0;32m    251\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\saiki\\IITB\\BTP1\\graphretrievaltoolkit-main\\graphretrievaltoolkit-main\\sgmatch\\modules\\propagation.py:180\u001b[0m, in \u001b[0;36mGraphProp._compute_node_update\u001b[1;34m(self, node_features, node_inputs)\u001b[0m\n\u001b[0;32m    178\u001b[0m node_inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39munsqueeze(node_inputs, \u001b[39m0\u001b[39m)\n\u001b[0;32m    179\u001b[0m node_features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39munsqueeze(node_features, \u001b[39m0\u001b[39m)\n\u001b[1;32m--> 180\u001b[0m _, new_node_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mGRU(node_inputs, node_features)\n\u001b[0;32m    181\u001b[0m new_node_features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqueeze(new_node_features)\n\u001b[0;32m    182\u001b[0m \u001b[39mreturn\u001b[39;00m new_node_features\n",
      "File \u001b[1;32mc:\\Users\\saiki\\IITB\\env_general\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\saiki\\IITB\\env_general\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:996\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    991\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    992\u001b[0m     \u001b[39m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    993\u001b[0m     \u001b[39m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m    994\u001b[0m     hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m--> 996\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_forward_args(\u001b[39minput\u001b[39;49m, hx, batch_sizes)\n\u001b[0;32m    997\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    998\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[0;32m    999\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n",
      "File \u001b[1;32mc:\\Users\\saiki\\IITB\\env_general\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:253\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_forward_args\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]):\n\u001b[1;32m--> 253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_input(\u001b[39minput\u001b[39;49m, batch_sizes)\n\u001b[0;32m    254\u001b[0m     expected_hidden_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_hidden_size(\u001b[39minput\u001b[39m, batch_sizes)\n\u001b[0;32m    256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001b[1;32mc:\\Users\\saiki\\IITB\\env_general\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:218\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    215\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput must have \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m dimensions, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    216\u001b[0m             expected_input_dim, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()))\n\u001b[0;32m    217\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m--> 218\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    219\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    220\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 32, got 16"
     ]
    }
   ],
   "source": [
    "train(train_loader,val_loader,model,criterion,optimizer,device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
